"""
Factory pattern script to generate 400 Prefect flows with various name patterns.
"""
import asyncio
import time
import argparse
from prefect import flow


# Configuration: prefix patterns and their counts
FLOW_PATTERNS = {
    "bird": 50,
    "latte": 50,
    "keyboard": 25,
    "cloud": 50,
    "ocean": 50,
    "mountain": 25,
    "river": 25,
    "forest": 50,
    "desert": 25,
    "city": 50,
}


def create_flow_factory(prefix: str, index: int):
    """
    Factory function to create a no-op Prefect flow with a given prefix and index.

    Args:
        prefix: The prefix for the flow name
        index: The numeric index for this flow

    Returns:
        A decorated Prefect flow function
    """
    flow_name = f"{prefix}-{index:03d}"

    @flow(name=flow_name)
    def generated_flow():
        """No-op flow generated by factory pattern."""
        pass

    return generated_flow


# Generate all flows dynamically
flows = []
for prefix, count in FLOW_PATTERNS.items():
    for i in range(1, count + 1):
        generated_flow = create_flow_factory(prefix, i)
        flows.append(generated_flow)
        # Register the flow in the module's namespace
        globals()[f"{prefix}_{i:03d}"] = generated_flow


async def submit_flow_run(flow_func, index: int):
    """Submit a single flow run asynchronously in a thread pool."""
    try:
        await asyncio.to_thread(flow_func)
        if index % 50 == 0:
            print(f"Submitted {index} flows...")
        return True
    except Exception as e:
        print(f"Error in flow {index}: {e}")
        return False


async def run_all_flows():
    """Submit all 400 flows concurrently using asyncio."""
    print(f"Submitting {len(flows)} flow runs concurrently...\n")
    start_time = time.time()

    tasks = [submit_flow_run(flow, i+1) for i, flow in enumerate(flows)]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    successful = sum(1 for r in results if r is True)
    elapsed = time.time() - start_time

    print(f"\nâœ“ Successfully completed {successful}/{len(flows)} flow runs")
    print(f"Total time: {elapsed:.2f}s")


async def deploy_all_flows():
    """Create deployments for all 400 flows using serve."""
    print(f"Creating deployments for {len(flows)} flows...\n")

    # Collect all serve coroutines
    serve_tasks = []
    for flow_func in flows:
        # Use asyncio.to_thread for the synchronous serve() call
        serve_tasks.append(asyncio.to_thread(flow_func.serve, name=flow_func.name))

    print(f"Starting {len(serve_tasks)} deployment servers...\n")

    # Run all serve calls concurrently - they will keep running
    await asyncio.gather(*serve_tasks)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate and run/deploy 400 Prefect flows")
    parser.add_argument(
        "--deploy",
        action="store_true",
        help="Create deployments for all flows instead of running them"
    )
    args = parser.parse_args()

    print(f"Generated {len(flows)} flows with the following patterns:")
    for prefix, count in FLOW_PATTERNS.items():
        print(f"  - {prefix}-*: {count} flows")
    print(f"\nTotal: {sum(FLOW_PATTERNS.values())} flows\n")

    if args.deploy:
        asyncio.run(deploy_all_flows())
    else:
        asyncio.run(run_all_flows())
