from prefect import flow, task
from prefect.logging import get_run_logger
from prefect_dask import DaskTaskRunner
from prefect.assets import Asset, AssetProperties, materialize
from prefect.artifacts import create_markdown_artifact
import time
import sys
from datetime import datetime

# Define a base asset for this flow
base_processing_asset = Asset(
    key="s3://parallel-processing/base/database",
    properties=AssetProperties(
        name="Parallel Processing Base Database",
        description="Base database for parallel sequential processing workflow",
        owners=["data-engineering"],
        url="https://prefect.io"
    )
)

@materialize(base_processing_asset)
def materialize_base_database():
    """Initialize the base processing database"""
    return {"status": "materialized", "timestamp": datetime.now().isoformat()}

@task
def long_running_task_with_asset(branch_id: int, task_id: int, duration_seconds: int = 1):
    """
    A long-running task that generates logs, materializes a unique asset, and creates an artifact.

    Args:
        branch_id: Identifier for the parallel branch
        task_id: Identifier for this task within the branch
        duration_seconds: How many seconds the task should run
    """
    logger = get_run_logger()

    logger.info(f"Branch {branch_id}, Task {task_id} starting - will run for {duration_seconds} second(s)")

    # Create a unique asset for this branch/task combination
    asset_key = f"s3://parallel-processing/branch_{branch_id}/task_{task_id}/data"

    dynamic_asset = Asset(
        key=asset_key,
        properties=AssetProperties(
            name=f"Branch {branch_id} Task {task_id} Output",
            description=f"Asset generated by branch {branch_id}, task {task_id} in parallel sequential flow",
            owners=["Search & Rescue"],
            url="https://prefect.io"
        )
    )

    # Materialize the asset with dependency on base database
    @materialize(dynamic_asset, asset_deps=[base_processing_asset], by="python")
    def materialize_task_asset():
        logger.info(f"Materializing asset for Branch {branch_id}, Task {task_id}")
        return {
            "branch_id": branch_id,
            "task_id": task_id,
            "timestamp": datetime.now().isoformat(),
            "duration_seconds": duration_seconds
        }

    # Run the materialization
    asset_data = materialize_task_asset()

    # Simulate long-running work with progress logging
    for second in range(duration_seconds):
        logger.info(f"Branch {branch_id}, Task {task_id} - Second {second + 1}/{duration_seconds} - {datetime.now().isoformat()}")
        time.sleep(1)

    # Create a unique artifact for this task
    artifact_markdown = f"""# Task Completion Report

## Task Details
- **Branch ID**: {branch_id}
- **Task ID**: {task_id}
- **Duration**: {duration_seconds} seconds
- **Completion Time**: {datetime.now().isoformat()}

## Asset Information
- **Asset Key**: `{asset_key}`
- **Asset Name**: {dynamic_asset.properties.name}

## Processing Summary
This task completed successfully after processing for {duration_seconds} seconds.
The task was part of branch {branch_id} and was task number {task_id} in the sequence.

## Asset Data
```json
{asset_data}
```

## Status
✅ **COMPLETED**
"""

    create_markdown_artifact(
        key=f"branch-{branch_id}-task-{task_id}-report",
        markdown=artifact_markdown,
        description=f"Completion report for Branch {branch_id}, Task {task_id}"
    )

    logger.info(f"Branch {branch_id}, Task {task_id} completed after {duration_seconds} second(s)")
    logger.info(f"Created artifact: branch-{branch_id}-task-{task_id}-report")
    logger.info(f"Materialized asset: {asset_key}")

    return {
        "branch_id": branch_id,
        "task_id": task_id,
        "asset_key": asset_key,
        "artifact_key": f"branch-{branch_id}-task-{task_id}-report",
        "completion_time": datetime.now().isoformat()
    }

@flow(task_runner=DaskTaskRunner())
def parallel_sequential_with_assets(num_parallel: int = 30, num_sequential: int = 10, duration_seconds: int = 20):
    """
    Runs multiple parallel branches, each containing sequential tasks.
    Each task materializes a unique asset and creates an artifact.

    Args:
        num_parallel: Number of parallel branches (default: 30)
        num_sequential: Number of sequential tasks per branch (default: 10)
        duration_seconds: Duration in seconds for each task (default: 20)
    """
    logger = get_run_logger()

    # Initialize the base processing database asset
    logger.info("Materializing base processing database asset")
    materialize_base_database()

    branches = []

    logger.info(f"Starting {num_parallel} parallel branches with {num_sequential} sequential tasks each")

    for branch in range(num_parallel):
        branch_tasks = []

        for seq_task in range(num_sequential):
            if seq_task == 0:
                # First task in branch - submit immediately
                result = long_running_task_with_asset.submit(branch + 1, seq_task + 1, duration_seconds)
            else:
                # Subsequent tasks wait for previous task
                result = long_running_task_with_asset.submit(
                    branch + 1,
                    seq_task + 1,
                    duration_seconds,
                    wait_for=[branch_tasks[-1]]
                )

            branch_tasks.append(result)

        branches.append(branch_tasks)

    # Wait for all branches to complete and collect results
    all_results = []
    for branch_idx, branch_tasks in enumerate(branches):
        logger.info(f"Collecting results from branch {branch_idx + 1}")
        for task_result in branch_tasks:
            all_results.append(task_result.result())

    logger.info(f"All {len(all_results)} tasks completed successfully")
    logger.info(f"Created {len(all_results)} assets and {len(all_results)} artifacts")

    # Create a summary artifact
    summary_markdown = f"""# Parallel Sequential Flow Summary

## Flow Configuration
- **Parallel Branches**: {num_parallel}
- **Sequential Tasks per Branch**: {num_sequential}
- **Task Duration**: {duration_seconds} seconds
- **Total Tasks**: {len(all_results)}

## Execution Summary
- **Total Assets Created**: {len(all_results)}
- **Total Artifacts Created**: {len(all_results) + 1} (including this summary)
- **Completion Time**: {datetime.now().isoformat()}

## Branch Results
"""

    for branch_idx in range(num_parallel):
        summary_markdown += f"\n### Branch {branch_idx + 1}\n"
        branch_results = [r for r in all_results if r['branch_id'] == branch_idx + 1]
        for result in branch_results:
            summary_markdown += f"- Task {result['task_id']}: ✅ Asset: `{result['asset_key']}`\n"

    summary_markdown += "\n## Status\n✅ **ALL TASKS COMPLETED SUCCESSFULLY**"

    create_markdown_artifact(
        key="parallel-sequential-flow-summary",
        markdown=summary_markdown,
        description=f"Summary report for parallel sequential flow with {num_parallel} branches"
    )

    return all_results

if __name__ == "__main__":
    parallel_sequential_with_assets.serve(
        name="parallel-sequential-with-assets",
        parameters={
            "num_parallel": 30,
            "num_sequential": 10,
            "duration_seconds": 20
        }
    )