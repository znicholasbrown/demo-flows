prefect-version: null
name: null

# preparation steps
build: null
push: null

# runtime steps
pull:
- prefect.deployments.steps.git_clone:
    repository: https://github.com/znicholasbrown/demo-flows.git
    branch: main

# deployment configurations
deployments:
  - name: ðŸ¤ŒðŸ¤Œ
    version_type: vcs:git
    tags: ['pasta', 'parmesan', 'italian', 'pasta-parmesan']
    description: null
    schedules: []

    # flow-specific fields
    entrypoint: versioning/versiano_reggiano.py:versiano_reggiano
    parameters: {}

    # infra-specific fields
    work_pool:
      name: managed
      work_queue_name: secondary
      job_variables: {}

  - name: process-node-map
    tags: ['process', 'node', 'map']
    description: Process a node map
    schedules: []
    entrypoint: process_node_map.py:process_node_map
    parameters: {
      "sleep_seconds_range_per_node": [5.0, 15.0],
      "number_nodes": 20
    }
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}

  - name: dungeon-campaign
    tags: ['dungeon', 'campaign']
    description: Run a dungeon campaign
    schedules: []
    entrypoint: dungeon_campaign_flow.py:dungeon_campaign_flow
    parameters: {
      "num_parties": 3,
      "rooms_per_party": 4
    }
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}

  - name: default
    tags: ['scraper', 'beautifulsoup']
    description: Scrape a webpage and size-rank the elements
    schedules: []

    # flow-specific fields
    entrypoint: analyze_webpage_elements.py:analyze_webpage
    parameters: {
      "url": "https://prefect.io/pricing"
    }
    enforce_parameter_schema: false

    # infra-specific fields
    work_pool:
      name: managed
      work_queue_name: default
      job_variables:
        pip_packages: ["beautifulsoup4"]

  # assets
  - name: default
    version: null
    tags: ['ml', 'assets']
    concurrency_limit: null
    description: Flow to train ML models
    entrypoint: assets/main.py:train_models
    parameters: {}
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}
    schedules: []
  - name: default
    version: null
    tags: ['analytics', 'assets']
    concurrency_limit: null
    description: Flow to run analytics and quality checks
    entrypoint: assets/main.py:run_analytics_and_quality
    parameters: {}
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}
    schedules: []
  - name: default
    version: null
    tags: ['assets']
    concurrency_limit: null
    description: Main pipeline flow
    entrypoint: assets/main.py:run_pipeline
    parameters: {}
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}
    schedules: []
  - name: default
    version: null
    tags: ['assets']
    concurrency_limit: null
    description: Data Ingestion
    entrypoint: assets/main.py:ingest_and_stage_data
    parameters: {}
    work_pool:
      name: nicholas
      work_queue_name: default
      job_variables: {}
    schedules: []

  - name: managed
    version: null
    tags: ['scaling']
    concurrency_limit: null
    description: Scaling test
    entrypoint: scale.py:scale_flow
    parameters: {}
    work_pool:
      name: nicholas-managed-staging
      work_queue_name: default
      job_variables: {}
    schedules: []